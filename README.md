
## Python
used python to explore the data and tried understand the data, created two different solutions to write into csv

## Spark
draft_code_inital_understanding_data - This process helped to understand the data and complete the process and write to a csv file. But this solution is not so dynamic in nature to read the child and parent combinations.

Solution - This is the final version of the code.I have created a generic UDF function that can dynamically explode the array and struct data. I have provided the html and scala file. 

Just need to remove the location of the file and can be ran in the databricks or spark cluster.

# Files Provided 

1. All the output files are in the spark -> result
2. solutions are under spark -> code

# Architecture
This conatins a PDF that explains the highlevel design for the architecture question
